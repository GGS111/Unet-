{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "theoretical-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Первый класс для двойных конволюций\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
    "    ):\n",
    "        super(UNET, self).__init__()\n",
    "        #Собираем модули\n",
    "        self.ups = nn.ModuleList() #Модуль для декодинга с повышением.\n",
    "        self.downs = nn.ModuleList() #Модуль для энкодинга с понижением.\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #Макс пул для понижения\n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature)) #Тут просто применяем даблКонв\n",
    "            in_channels = feature #Переприсваиваем размер карты признаков\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            #Первая часть отвечает за Апсемплинг, обратный макспулинг. Так как у нас будет конкатенация\n",
    "            #Карты признаков от скип.коннекшена, то первое значение умножаем на 2\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            #Делаем ДаблКонв\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "        \n",
    "        #Самая нижняя строка\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        #Финальная конволюция с ядром 1х1\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        #С помощью этого цикла проходимся и делаем все преобразования до нижнего уровня, и собираем скип.коннекшен\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        #Преобразования самого нижнего уровня\n",
    "        x = self.bottleneck(x)\n",
    "        #Реверс скипконнекшена\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        #Цикл для поднятия. Смысл в том, что мы делаем шаг 2, так как у нас есть две операции. Даблконв и апсемплинг\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            #Сначала мы делаем апсемплинг\n",
    "            x = self.ups[idx](x)\n",
    "            #Далее берем скипконнекшен и делем индекс на 2, чтобы брать его корректно\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            #Проверка на совпадение размеров экнодинга с декондингом перед контактенацией.\n",
    "            #Тут важно понимать, что в классической модели размер изображения на декодинге меньше чем на экнодинге\n",
    "            #Поэтому делаем ресайз 3 4 каналов энкодинга, то есть ресайзим размер изображения\n",
    "            if x.shape != skip_connection.shape:\n",
    "                skip_connection = TF.resize(skip_connection, size=x.shape[2:])\n",
    "            \n",
    "            #Конкатенируем карты признаков\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            #Применяем ДаблКонв к конкатенируемому элементу, причем берем индексы 1/3/5 и т.д.\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-issue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "organic-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([2, 512, 56, 56])\n",
      "skip_connection torch.Size([2, 512, 64, 64])\n",
      "x.shape torch.Size([2, 256, 104, 104])\n",
      "skip_connection torch.Size([2, 256, 136, 136])\n",
      "x.shape torch.Size([2, 128, 200, 200])\n",
      "skip_connection torch.Size([2, 128, 280, 280])\n",
      "x.shape torch.Size([2, 64, 392, 392])\n",
      "skip_connection torch.Size([2, 64, 568, 568])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 570, 570]             576\n",
      "       BatchNorm2d-2         [-1, 64, 570, 570]             128\n",
      "              ReLU-3         [-1, 64, 570, 570]               0\n",
      "            Conv2d-4         [-1, 64, 568, 568]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 568, 568]             128\n",
      "              ReLU-6         [-1, 64, 568, 568]               0\n",
      "        DoubleConv-7         [-1, 64, 568, 568]               0\n",
      "         MaxPool2d-8         [-1, 64, 284, 284]               0\n",
      "            Conv2d-9        [-1, 128, 282, 282]          73,728\n",
      "      BatchNorm2d-10        [-1, 128, 282, 282]             256\n",
      "             ReLU-11        [-1, 128, 282, 282]               0\n",
      "           Conv2d-12        [-1, 128, 280, 280]         147,456\n",
      "      BatchNorm2d-13        [-1, 128, 280, 280]             256\n",
      "             ReLU-14        [-1, 128, 280, 280]               0\n",
      "       DoubleConv-15        [-1, 128, 280, 280]               0\n",
      "        MaxPool2d-16        [-1, 128, 140, 140]               0\n",
      "           Conv2d-17        [-1, 256, 138, 138]         294,912\n",
      "      BatchNorm2d-18        [-1, 256, 138, 138]             512\n",
      "             ReLU-19        [-1, 256, 138, 138]               0\n",
      "           Conv2d-20        [-1, 256, 136, 136]         589,824\n",
      "      BatchNorm2d-21        [-1, 256, 136, 136]             512\n",
      "             ReLU-22        [-1, 256, 136, 136]               0\n",
      "       DoubleConv-23        [-1, 256, 136, 136]               0\n",
      "        MaxPool2d-24          [-1, 256, 68, 68]               0\n",
      "           Conv2d-25          [-1, 512, 66, 66]       1,179,648\n",
      "      BatchNorm2d-26          [-1, 512, 66, 66]           1,024\n",
      "             ReLU-27          [-1, 512, 66, 66]               0\n",
      "           Conv2d-28          [-1, 512, 64, 64]       2,359,296\n",
      "      BatchNorm2d-29          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-30          [-1, 512, 64, 64]               0\n",
      "       DoubleConv-31          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-32          [-1, 512, 32, 32]               0\n",
      "           Conv2d-33         [-1, 1024, 30, 30]       4,718,592\n",
      "      BatchNorm2d-34         [-1, 1024, 30, 30]           2,048\n",
      "             ReLU-35         [-1, 1024, 30, 30]               0\n",
      "           Conv2d-36         [-1, 1024, 28, 28]       9,437,184\n",
      "      BatchNorm2d-37         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-38         [-1, 1024, 28, 28]               0\n",
      "       DoubleConv-39         [-1, 1024, 28, 28]               0\n",
      "  ConvTranspose2d-40          [-1, 512, 56, 56]       2,097,664\n",
      "           Conv2d-41          [-1, 512, 54, 54]       4,718,592\n",
      "      BatchNorm2d-42          [-1, 512, 54, 54]           1,024\n",
      "             ReLU-43          [-1, 512, 54, 54]               0\n",
      "           Conv2d-44          [-1, 512, 52, 52]       2,359,296\n",
      "      BatchNorm2d-45          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-46          [-1, 512, 52, 52]               0\n",
      "       DoubleConv-47          [-1, 512, 52, 52]               0\n",
      "  ConvTranspose2d-48        [-1, 256, 104, 104]         524,544\n",
      "           Conv2d-49        [-1, 256, 102, 102]       1,179,648\n",
      "      BatchNorm2d-50        [-1, 256, 102, 102]             512\n",
      "             ReLU-51        [-1, 256, 102, 102]               0\n",
      "           Conv2d-52        [-1, 256, 100, 100]         589,824\n",
      "      BatchNorm2d-53        [-1, 256, 100, 100]             512\n",
      "             ReLU-54        [-1, 256, 100, 100]               0\n",
      "       DoubleConv-55        [-1, 256, 100, 100]               0\n",
      "  ConvTranspose2d-56        [-1, 128, 200, 200]         131,200\n",
      "           Conv2d-57        [-1, 128, 198, 198]         294,912\n",
      "      BatchNorm2d-58        [-1, 128, 198, 198]             256\n",
      "             ReLU-59        [-1, 128, 198, 198]               0\n",
      "           Conv2d-60        [-1, 128, 196, 196]         147,456\n",
      "      BatchNorm2d-61        [-1, 128, 196, 196]             256\n",
      "             ReLU-62        [-1, 128, 196, 196]               0\n",
      "       DoubleConv-63        [-1, 128, 196, 196]               0\n",
      "  ConvTranspose2d-64         [-1, 64, 392, 392]          32,832\n",
      "           Conv2d-65         [-1, 64, 390, 390]          73,728\n",
      "      BatchNorm2d-66         [-1, 64, 390, 390]             128\n",
      "             ReLU-67         [-1, 64, 390, 390]               0\n",
      "           Conv2d-68         [-1, 64, 388, 388]          36,864\n",
      "      BatchNorm2d-69         [-1, 64, 388, 388]             128\n",
      "             ReLU-70         [-1, 64, 388, 388]               0\n",
      "       DoubleConv-71         [-1, 64, 388, 388]               0\n",
      "           Conv2d-72          [-1, 1, 388, 388]              65\n",
      "================================================================\n",
      "Total params: 31,036,481\n",
      "Trainable params: 31,036,481\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.25\n",
      "Forward/backward pass size (MB): 3279.44\n",
      "Params size (MB): 118.39\n",
      "Estimated Total Size (MB): 3399.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vgg = UNET(1, 1)\n",
    "summary(vgg, (1, 572, 572))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-shuttle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
